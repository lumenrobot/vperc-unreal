---
title: "2D to 3D Reconstruction for Virtual Perception"
author: "Sigit Ari Wijanarko, Hendy Irawan"
date: "Saturday, April 04, 2015"
output:
  html_document:
    self_contained: no
---

## Units & Coordinate System

Lihat: [Lumen Units and 2D/3D Coordinate System](coordinates.html)

## 3D Reconstruction

Formula: http://docs.opencv.org/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html

```
s * UV = CM * Rt * XYZ
```

s adalah pembagi dari UV, bila UV = (20, 10, 2) maka u = 20/2 = 10, v = 10/2 = 5.

$$\mathbf{CM} = \left[\begin{array}
{rrr}
f_x &    0 & c_x \\
  0 & -f_y & c_y \\
  0 &    0 &   1
\end{array}\right]
$$

$-f_y$ diminuskan karena di gambar 2D, pojok atas adalah $v=0$ dan bawah adalah misalnya $v=240$ (untuk dimensi 320×240); padahal di 3D bawah adalah $y<0$ dan atas adalah $y>0$.

Untuk mendapatkan $f_x$ dan $f_y$, kita menentukan dulu focal length dan ukuran "sensor".
Anggap focal length ($F$) 35mm. Dan sensor 36mm x 24mm (Full-frame). Trus resolusi gambar 320×240.

* $s_x$ = image width(px) / sensor width(mm) = 320px / 36mm = 8.9px/mm
* $s_y$ = image height(px) / sensor height(mm) = 240px / 24mm = 10px/mm
* kalo square pixel, harusnya $s_x = s_y$

Maka

* $f_x$ = F * sx = 35mm * 8.9 = 311.1 px
* $f_y$ = F * sy = 35mm * 10 = 350 px
* $c_x$ (image horizontal center) = imageWidth / 2
* $c_y$ (image vertical center) = imageHeight / 2

Maka

```{r}
library(pander)
# 35mm lens on Sony Alpha 7r
focalLength <- 35 #mm
imageWidth <- 320 #px
imageHeight <- 240 #Px
sensorWidth <- 36 #mm
sensorHeight <- 24 #mm
centerX <- imageWidth / 2 #px
centerY <- imageHeight / 2 #px
CM <- matrix(c(focalLength * imageWidth / sensorWidth, 0, centerX,
               0, -focalLength * imageHeight / sensorHeight, centerY,
               0, 0, 1), ncol=3, byrow=TRUE)
pander(CM, caption='camera matrix')
```

Contoh: Samsung Galaxy S4:

* Aperture size F2.2
* Focal length (35mm equivalent): 31 mm --> harus dikonversi ke focal length fisik = 4.3mm (http://www.digified.net/focallength/)
* Camera sensor size: 1/3.06" (diagonal: 0.3268" = 8.3mm, dimensi: 6.64mm x 4.98mm)
* Pixel size: 1.14 μm

```{r}
# Samsung Galaxy S4
focalLength <- 4.3 #mm
imageWidth <- 320 #px
imageHeight <- 240 #px
sensorWidth <- 6.64 #mm
sensorHeight <- 4.98 #mm
center <- c(imageWidth / 2, imageHeight / 2) #px
names(center) <- c('u', 'v')
f <- c(focalLength * imageWidth / sensorWidth, focalLength * imageHeight / sensorHeight)
names(f) <- c('x', 'y')
pander(f)
all.equal(f['x'], f['y'], check.names=FALSE) # harusnya f['x'] ~ f['y'] yaaa!!
CM <- matrix(c(f['x'],       0, center['u'],
                    0, -f['y'], center['v'],
                    0,       0,           1),
             ncol=3, byrow=TRUE)
pander(CM, caption='camera matrix')
```

Kalau udah punya CM maka perlu bikin joint rotation-translation matrix. Ini Hendy agak bingung jadi biarin Sigit aja yang pusing :p

```{r}
theta <- 0*pi # harusnya ini gamma, lihat penjelasan di bawah tentang rotasi 3D
t <- c(0, 0, 0)
names(t) <- c('x', 'y', 'z')
pander(t)
# rotasi ini sebenarnya masih RZ, belum R
Rt <- matrix(c(cos(theta), -sin(theta), 0, t['x'],
               sin(theta),  cos(theta), 0, t['y'],
               0,           0,          1, t['z']),
             ncol=4, byrow=TRUE)
pander(Rt)
```

Dari sini kita bisa memproyeksikan sebuah titik 3D ke 2D.
Kalau benar, maka untuk dari 2D ke 3D ya tinggal dibalik.

```{r}
                # x    y    z   1
XYZ <- matrix(c(  0,   0,0.01,  1, # persis di tengah
                  0,   0,   1,  1, # persis di tengah, agak ke depan
                 -1,   0,   1,  1, # depan, agak ke kiri
                  3,   0,   1,  1, # depan, lebih ke kanan
                  0,   1,   1,  1, # depan, atas
                  0,  -3,   1,  1, # depan, lebih ke bawah
                 -1,  -3,   1,  1, # depan, kiri atas
                  2,   4,   1,  1, # depan, kanan atas
                  0,   0,   5,  1, # persis di tengah, depan banget
                 -1,   0,   5,  1, # depan banget, agak ke kiri
                  3,   0,   5,  1, # depan banget, lebih ke kanan
                  0,   1,   5,  1, # depan banget, atas
                  0,  -3,   5,  1, # depan banget, lebih ke bawah
                 -1,  -3,   5,  1, # depan banget, kiri atas
                  2,   4,   5,  1),# depan banget, kanan atas
              ncol=4, byrow=TRUE)
colnames(XYZ) <- c('x', 'y', 'z', '1')
pander(XYZ)
```

Tinggal dikalikan dech:

```{r}
sUV <- t(CM %*% Rt %*% XYZ[4,]) # point ke-4
names(sUV) <- c('u', 'v', 's')
pander(sUV)
if (sUV['s'] != 0) UV <- sUV / sUV['s'] else UV <- sUV
pander(UV)
```

Atau ramean:

```{r}
sUV <- t(CM %*% Rt %*% t(XYZ))
colnames(sUV) <- c('su', 'sv', 's')
pander(sUV)
UV <- matrix(ncol = 3, nrow = nrow(sUV))
colnames(UV) <- c('u', 'v', 's')
UV[,'u'] <- sUV[,'su'] / sUV[,'s']
UV[,'v'] <- sUV[,'sv'] / sUV[,'s']
UV[,'s'] <- sUV[,'s']
pander(UV)
```

Yuk coba kita plot.

```{r, warning=FALSE}
library(ggplot2)
df <- data.frame(UV)
df$id <- rownames(df)
df$salpha <- min(max(df$s/5, 0), 1)
df$dsize <- pmin(10/df$s, 20)
pander(df)
ggplot(df, aes(x=u, y=v)) + #geom_point(color=rownames(df)) +
  geom_text(aes(label=id, color=id)) + #,size=dsize
  scale_y_reverse() +
  ggtitle('Note that image range is (0,0)..(320,240), and point ke(n) = ke(n+7) cuma beda z')
```

Experimen apabila Rt diganti sedikit:

```{r, warning=FALSE}
t <- c(1, 0, 0)
names(t) <- c('x', 'y', 'z')
pander(t)
Rt <- matrix(c(cos(theta), -sin(theta), 0, t['x'],
               sin(theta),  cos(theta), 0, t['y'],
               0,           0,          1, t['z']),
             ncol=4, byrow=TRUE)
pander(Rt)

# ramean
sUV <- t(CM %*% Rt %*% t(XYZ))
colnames(sUV) <- c('su', 'sv', 's')
#sUV
UV <- matrix(ncol = 3, nrow = nrow(sUV))
colnames(UV) <- c('u', 'v', 's')
UV[,'u'] <- sUV[,'su'] / sUV[,'s']
UV[,'v'] <- sUV[,'sv'] / sUV[,'s']
UV[,'s'] <- sUV[,'s']
#UV

# plot
library(ggplot2)
df <- data.frame(UV)
pander(df)
ggplot(df, aes(x=u, y=v)) + #geom_point(color=rownames(df)) +
  geom_text(label=rownames(df), color=rownames(df)) +
  scale_y_reverse() +
  ggtitle('Note that image range is (0,0)..(320,240), and point ke(n) = ke(n+7) cuma beda z')
```

## Memplot 'lantai'


```{r}
# create 100 lattice points (10x10) spanning from X=-2..+2 and Z =0..10, Y constant = -1
XYZ <- matrix(nrow = 100, ncol=4)
colnames(XYZ) <- c('x', 'y', 'z', 'dummy')
for (i in 0:9) {
  for (j in 0:9) {
    x <- -2 + i*0.4
    y <- -1
    z <- 0 + j*1
    XYZ[i * 10 + j + 1,] <- c(x, y, z, 1)
  }
}
pander(XYZ)
```

Bila ty = 0:

```{r, warning=FALSE}
theta <- 0*pi
t <- c(0, 0, 0)
names(t) <- c('x', 'y', 'z')
pander(t)
Rt <- matrix(c(cos(theta), -sin(theta), 0, t['x'],
               sin(theta),  cos(theta), 0, t['y'],
               0,           0,          1, t['z']),
             ncol=4, byrow=TRUE)
pander(Rt)

# ramean
sUV <- t(CM %*% Rt %*% t(XYZ))
colnames(sUV) <- c('su', 'sv', 's')
#sUV
UV <- matrix(ncol = 3, nrow = nrow(sUV))
colnames(UV) <- c('u', 'v', 's')
UV[,'u'] <- sUV[,'su'] / sUV[,'s']
UV[,'v'] <- sUV[,'sv'] / sUV[,'s']
UV[,'s'] <- sUV[,'s']
#UV

# plot
library(ggplot2)
df <- data.frame(UV)
#df
ggplot(df, aes(x=u, y=v)) + #geom_point(color=rownames(df)) +
  geom_point(aes(color=s, size=10-s), alpha=0.8) +
  scale_y_reverse(limits=c(360, 0), breaks=c(0, 120, 240)) + 
  scale_x_continuous(limits=c(0, 480), breaks=c(0, 160, 320)) +
  ggtitle('2Dimage range is (0,0)..(320,240)')
```

Bila theta = pi/11: (terhadap sumbu z[depan-belakang])

```{r, warning=FALSE}
theta <- pi/11
t <- c(0, 0, 0)
names(t) <- c('x', 'y', 'z')
pander(t)
Rt <- matrix(c(cos(theta), -sin(theta), 0, t['x'],
               sin(theta),  cos(theta), 0, t['y'],
               0,           0,          1, t['z']),
             ncol=4, byrow=TRUE)
pander(Rt)

# ramean
sUV <- t(CM %*% Rt %*% t(XYZ))
colnames(sUV) <- c('su', 'sv', 's')
#sUV
UV <- matrix(ncol = 3, nrow = nrow(sUV))
colnames(UV) <- c('u', 'v', 's')
UV[,'u'] <- sUV[,'su'] / sUV[,'s']
UV[,'v'] <- sUV[,'sv'] / sUV[,'s']
UV[,'s'] <- sUV[,'s']
#UV

# plot
library(ggplot2)
df <- data.frame(UV)
#df
ggplot(df, aes(x=u, y=v)) + #geom_point(color=rownames(df)) +
  geom_point(aes(color=s, size=10-s), alpha=0.8) +
  scale_y_reverse(limits=c(360, 0), breaks=c(0, 120, 240)) + 
  scale_x_continuous(limits=c(0, 480), breaks=c(0, 160, 320)) +
  ggtitle('2Dimage range is (0,0)..(320,240)')
```

Bila ty = -1: (kamera agak ke atas)

```{r, warning=FALSE}
t <- c(0, -1, 0)
names(t) <- c('x', 'y', 'z')
pander(t)
Rt <- matrix(c(cos(theta), -sin(theta), 0, t['x'],
               sin(theta),  cos(theta), 0, t['y'],
               0,           0,          1, t['z']),
             ncol=4, byrow=TRUE)
pander(Rt)

# ramean
sUV <- t(CM %*% Rt %*% t(XYZ))
colnames(sUV) <- c('su', 'sv', 's')
#sUV
UV <- matrix(ncol = 3, nrow = nrow(sUV))
colnames(UV) <- c('u', 'v', 's')
UV[,'u'] <- sUV[,'su'] / sUV[,'s']
UV[,'v'] <- sUV[,'sv'] / sUV[,'s']
UV[,'s'] <- sUV[,'s']
#UV

# plot
library(ggplot2)
df <- data.frame(UV)
#df
ggplot(df, aes(x=u, y=v)) + #geom_point(color=rownames(df)) +
  geom_point(aes(color=s, size=10-s), alpha=0.8) +
  scale_y_reverse(limits=c(700, 0), breaks=c(0, 120, 240)) + 
  scale_x_continuous(limits=c(0, 1100), breaks=c(0, 160, 320)) +
  ggtitle('2Dimage range is (0,0)..(320,240)')
```

Bila ty = +2: (kamera di bawah lantai)

```{r, warning=FALSE}
t <- c(0, +2, 0)
names(t) <- c('x', 'y', 'z')
pander(t)
Rt <- matrix(c(cos(theta), -sin(theta), 0, t['x'],
               sin(theta),  cos(theta), 0, t['y'],
               0,           0,          1, t['z']),
             ncol=4, byrow=TRUE)
pander(Rt)

# ramean
sUV <- t(CM %*% Rt %*% t(XYZ))
colnames(sUV) <- c('su', 'sv', 's')
#sUV
UV <- matrix(ncol = 3, nrow = nrow(sUV))
colnames(UV) <- c('u', 'v', 's')
UV[,'u'] <- sUV[,'su'] / sUV[,'s']
UV[,'v'] <- sUV[,'sv'] / sUV[,'s']
UV[,'s'] <- sUV[,'s']
#UV

# plot
library(ggplot2)
df <- data.frame(UV)
#df
ggplot(df, aes(x=u, y=v)) + #geom_point(color=rownames(df)) +
  geom_point(aes(color=s, size=10-s), alpha=0.8) +
  scale_y_reverse(limits=c(700, 0), breaks=c(0, 120, 240)) + 
  scale_x_continuous(limits=c(0, 1100), breaks=c(0, 160, 320)) +
  ggtitle('2Dimage range is (0,0)..(320,240)')
```

## 3D Reconstruction from 2D

First, we multiply the CM with Rt:

```{r}
theta <- 0*pi
t <- c(0, 0, 0)
names(t) <- c('x', 'y', 'z')
pander(t)
Rt <- matrix(c(cos(theta), -sin(theta), 0, t['x'],
               sin(theta),  cos(theta), 0, t['y'],
               0,           0,          1, t['z']),
             ncol=4, byrow=TRUE)
colnames(Rt) <- c('r1', 'r2', 'r3', 't')
pander(Rt)

CMRt <- CM %*% Rt
pander(CMRt)
```

Bila diketahui: u, v, dan y dari object, maka:

```{r}
# xyz yang diinginkan: c(0.8, -1.0, 6.0)
# uv(s) adalah: c(187.6305 154.5382) -> kalau di imagespace, cuma c(188, 154, dummy=1) dan agak nggak akurat
# y adalah: -1
# dy (y object/lantai dikurangi y camera) = 0 - 1 = -1
# s = dy / (y hasil solve)
yObject <- 0 # lantai Lumen: y == 0
yCamera <- 1 # camera 1 meter di atas lantai
dy <- yObject - yCamera
uv <- c(188, 154, 1)
xyz <- solve(qr(CMRt), uv)
names(xyz) <- c('x', 'y', 'z')
pander(xyz)
# s = dy / (y hasil solve)
s <- dy / xyz['y']
pander(s)
# kalikan hasil solve dengan s, maka didapatkan xyz sebenarnya
# yaitu: c(0.8, -1.0, 6.0) +- galat
xyz <- xyz * s
pander(xyz)
```

Terus kita ingin mengetahui tinggi dari objek tersebut,
bila diketahui x,y,z,u,v dari kaki, lalu v dari ujung kepala.

```{r}
uv.head = c(188, 140, 1) # tingginya 14 pixel di camera
xyz.head <- solve(qr(CMRt), uv.head)
names(xyz.head) <- c('x', 'y', 'z')
pander(xyz.head)
# s sudah didapatkan di atas
# kalikan hasil solve dengan s, maka didapatkan xyz sebenarnya
# di mana bs dipastikan bahwa x.head == x.foot, z.head==z.foot
# kalau misalnya ga sama, berarti s-nya salah
# cuma belum dicoba kalau kameranya berotasi...
xyz.head <- xyz.head * s
pander(xyz.head)
pander(c(xyz.head['x'] == xyz['x'], xyz.head['z'] == xyz['z']))
# tinggi orang adalah xyz.head[y] - xyz.foot[y]
person.height <- xyz.head['y'] - xyz['y']
pander(person.height)
```

dan dengan yang cara yang sama, harusnya ini juga bisa digunakan untuk mengetahui lebar (kiri..kanan) dari objek / batas koordinat menurut sumbu x.

## Implementasi di C++

Selain fungsi dasar [matrix multiplication di OpenCV](http://docs.opencv.org/modules/core/doc/basic_structures.html#matrix-expressions), yang dibutuhkan adalah:

1. `qr`: QR Decomposition of Matrix.
2. `solve`: Solve a System of Equations

Ternyata sudah ada, yaitu [bool solve(InputArray src1, InputArray src2, OutputArray dst, int flags=DECOMP_LU)¶](http://docs.opencv.org/modules/core/doc/operations_on_arrays.html?highlight=solve#bool solve(InputArray src1, InputArray src2, OutputArray dst, int flags))

jadi kalo di R:

```{r, eval=FALSE}
xyz <- solve(qr(CMRt), uv)
```

di C++ jadi:

```
bool success = solve(CMRt, uv, xyz, DECOMP_QR);
```

## Pembuktian Model dari Realita Samsung Galaxy S4

Di kantor Bippo:

* ukuran ruangan:
  dz = (11.66667 + 6.9) * 0.3 = 5.57 m, dengan range: -2...+3.57
  dx = 12 * 0.3 = 3.6 m, dengan range: -1.4 .. +2.2
* Jarak kamera ke tembok (z) = 11.6667 ubin = 11.6667 * 0.3 = 3.5 m
* y kamera = 0.6m. Posisi kamera (0, 0.6, 0).
* y lantai = 0m
* tinggi objek (ubin) = 0.3m
* lebar objek (ubin)  = 0.3m
* rotasi terhadap horizon = awalnya 0 semua, tapi akan di
* posisi objek:
    1. 11 petak dari kamera (0, 0, 3.3)
    2. 10 petak dari kamera (0, 0, 3.0)
    3.  9 petak dari kamera (0, 0, 2.7)
    4.  8 petak dari kamera (0, 0, 2.4)
    5.  7 petak dari kamera (0, 0, 2.1)
    6.  6 petak dari kamera (0, 0, 1.8)
    7.  5 petak dari kamera (0, 0, 1.5)

## Rotasi 3D

Recall pedoman rotasi sebagai berikut:

* Pitch ($R_{cx}$):  Looking up and down (0=Straight Ahead, +Up, -Down).
* Roll ($R_{cy}$): Rotation about axis of screen, 0=Straight, +Clockwise, -CCW.
* Yaw ($R_{cz}$):  Rotating around (running in circles), 0=North, +West, -East. Kalo di Unreal: 0=East, +North, -South.

Dari [Rotation matrix: In three dimensions](https://en.wikipedia.org/wiki/Rotation_matrix#Basic_rotations):

$$R_cx(\alpha) = \begin{bmatrix}
  1 & 0 & 0 \\
  0 & \cos \alpha & -\sin \alpha \\
  0 & \sin \alpha & \cos \alpha
\end{bmatrix}
R_cy(\beta) = \begin{bmatrix}
  \cos \beta & 0 & \sin \beta \\
  0          & 1 & 0 \\
  -sin \beta & 0 & \cos \beta
\end{bmatrix}
R_cz(\gamma) = \begin{bmatrix}
  \cos \gamma & -\sin \gamma & 0 \\
  \sin \gamma &   cos \gamma & 0 \\
  0           & 0            & 1
\end{bmatrix}
$$

Untuk menggabungkan $R_cx$, $R_cy$, dan $R_cz$ kayaknya urutannya begini:

$$R_c = R_{cz(γ)} R_{cy(β)} R_{cx(α)}
$$

Perhatikan bahwa tugas $[R|t]$ adalah mentranslasi lalu merotasi titik 3D agar berada dalam koordinat kamera.
Setelah didapatkan $R_c$ yaitu rotasi kamera dan $t_c$ yaitu translasi kamera, kita bisa mencari $[R|t]$.
Untuk mendapatkan $[R|\mathbf{t}]$ dari posisi kamera $t_c$ dan rotasi kamera $R_c$, [maka](http://ksimek.github.io/2012/08/22/extrinsic/): ($^T$: transpose)

$$\left[
\begin{array}{c|c}
R & \mathbf{t} \\
\hline
\mathbf{0} & 1 \\
\end{array}
\right]
  = 
\left[
\begin{array}{c|c}
R_c^T & -R_c^{T} t_c \\
\hline
\mathbf{0} & 1 \\
\end{array}
\right]
$$

Dari [Rotation in 3D using OpenCV](http://jepsonsblog.blogspot.com/2012/11/rotation-in-3d-using-opencvs.html):

```
// Rotation matrices around the X, Y, and Z axis
Mat RX = (Mat_<double>(4, 4) <<
          1,          0,           0, 0,
          0, cos(alpha), -sin(alpha), 0,
          0, sin(alpha),  cos(alpha), 0,
          0,          0,           0, 1);
Mat RY = (Mat_<double>(4, 4) <<
          cos(beta), 0, -sin(beta), 0,
          0, 1,          0, 0,
          sin(beta), 0,  cos(beta), 0,
          0, 0,          0, 1);
Mat RZ = (Mat_<double>(4, 4) <<
          cos(gamma), -sin(gamma), 0, 0,
          sin(gamma),  cos(gamma), 0, 0,
          0,          0,           1, 0,
          0,          0,           0, 1);
// Composed rotation matrix with (RX, RY, RZ)
Mat R = RX * RY * RZ;
```
